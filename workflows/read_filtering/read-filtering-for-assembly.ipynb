{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read Filtering for Assembly Workflow\n",
    "This noteboook installs all docker containers; creates all directories; and runs all programs neccessary to implement a read filtering pipeline for use with metagenomics assembler software. For assembly minimal trimming is performed and the primary goal is to remove aapter sequences. The workflow first enables downloading and generating of all required docker containers, inputs, and drectories. Quality assesments are then executed using FastQC. Datasets are trimmed of adapter TruSeq sequences using Trimmomatic. FastQC dataset analyses are re-calculated over the trimmed datasets. Read 1 and Read 2 sequences are interleaven using Khmer. The example datasets provided as sample imputs are a subset of the Shakya M. et al.(doi 10.1111/1462-2920.12086) dataset which is described in the dataset-characteristics.ipynb notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Install Required Docker Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: osfclient in /home/oana/py3/lib/python3.5/site-packages\n",
      "Requirement already satisfied: six in /home/oana/py3/lib/python3.5/site-packages (from osfclient)\n",
      "Requirement already satisfied: requests in /home/oana/py3/lib/python3.5/site-packages (from osfclient)\n",
      "Requirement already satisfied: tqdm in /home/oana/py3/lib/python3.5/site-packages (from osfclient)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/oana/py3/lib/python3.5/site-packages (from requests->osfclient)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/oana/py3/lib/python3.5/site-packages (from requests->osfclient)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/oana/py3/lib/python3.5/site-packages (from requests->osfclient)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/oana/py3/lib/python3.5/site-packages (from requests->osfclient)\n",
      "Using default tag: latest\n",
      "latest: Pulling from biocontainers/fastqc\n",
      "Digest: sha256:7839537b143498ccc32214c4b02a235f7a10b0794064647323de0d5d5957f42b\n",
      "Status: Image is up to date for biocontainers/fastqc:latest\n",
      "0.36--4: Pulling from biocontainers/trimmomatic\n",
      "\n",
      "\u001b[1B95caeb02: Already exists \n",
      "\u001b[1Ba756c345: Already exists \n",
      "\u001b[1B60de4b27: Already exists \n",
      "\u001b[1Bc29a56fb: Already exists \n",
      "\u001b[1Bbb6634fc: Already exists \n",
      "\u001b[1B10677cff: Already exists \n",
      "\u001b[7B95caeb02: Already exists \n",
      "\u001b[1Bb3b2fa0d: Already exists \n",
      "\u001b[1BDigest: sha256:f162a5c4f2644a00e186a6e105e798d4bcdecddb653474ea7e42c915dc6a416b\n",
      "Status: Image is up to date for quay.io/biocontainers/trimmomatic:0.36--4\n",
      "2.1--py35_0: Pulling from biocontainers/khmer\n",
      "\n",
      "\u001b[1B95caeb02: Already exists \n",
      "\u001b[1Bc00e8b61: Already exists \n",
      "\u001b[1Bde50789a: Already exists \n",
      "\u001b[1B8b9f3d2a: Already exists \n",
      "\u001b[1B99a2256f: Already exists \n",
      "\u001b[1B336f2e44: Already exists \n",
      "\u001b[7B95caeb02: Already exists \n",
      "\u001b[1Bbb32200b: Already exists \n",
      "\u001b[1B1b1b4b4f: Already exists Digest: sha256:f82b5f6cc5d57ca9e1b4854f41ea088debaaf2d0b6043a7dc874466433ff35d1\n",
      "Status: Image is up to date for quay.io/biocontainers/khmer:2.1--py35_0\n",
      "2.11--1: Pulling from biocontainers/pandaseq\n",
      "\n",
      "\u001b[1B95caeb02: Already exists \n",
      "\u001b[1Ba756c345: Already exists \n",
      "\u001b[1B60de4b27: Already exists \n",
      "\u001b[1Bc29a56fb: Already exists \n",
      "\u001b[1Bbb6634fc: Already exists \n",
      "\u001b[1B10677cff: Already exists \n",
      "\u001b[7B95caeb02: Already exists \n",
      "\u001b[1Bb3b2fa0d: Already exists \n",
      "\u001b[1Bba8b5542: Pull complete 644MB/2.644MBB\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[KDigest: sha256:b4858e79d1bc7a7c40f5f33af34914dfea1007692db4a4fca3e95575b9fa63f5\n",
      "Status: Downloaded newer image for quay.io/biocontainers/pandaseq:2.11--1\n"
     ]
    }
   ],
   "source": [
    "# Install docker containers to run pipeline\n",
    "!docker pull biocontainers/fastqc\n",
    "!docker pull quay.io/biocontainers/trimmomatic:0.36--4\n",
    "!docker pull quay.io/biocontainers/khmer:2.1--py35_0\n",
    "!docker pull quay.io/biocontainers/pandaseq:2.11--1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Set up directories and download input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a working directory (/home/username/data) and download input datasets\n",
    "!mkdir /home/ubuntu/data\n",
    "!cd /home/ubuntu/data\n",
    "!pip install osfclient\n",
    "!osf -p dm938 fetch osfstorage/data/SRR606249_subset10_1.fq.gz\n",
    "!osf -p dm938 fetch osfstorage/data/SRR606249_subset10_2.fq.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run FastQC quality assesment tool over inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/oana/py3/lib/python3.5/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "!cd /home/oana/data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SRR606249_subset10_1_fastqc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-18b82a203b62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#\"SRR606249_subset10_1.fq.gz FastQC Report.html\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSRR606249_subset10_1_fastqc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"html5lib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m graph_alt_names = [\"Per base quality graph\", \"Per sequence quality graph\", \"Per base sequence content\", \"Per sequence GC content graph\", \"N content graph\", \n\u001b[1;32m     14\u001b[0m                        \"Sequence Length distribution\", \"Duplication level graph\",  \"Adapter graph\", \"Kmer graph\" ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SRR606249_subset10_1_fastqc' is not defined"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import argparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#if __name__ == '__main__':\n",
    "#    parser = argparse.ArgumentParser(description=\"python module to pull images from the HTML output file\")\n",
    "#    parser.add_argument(\"html_file\", help=\"HTML file to get images from \")\n",
    "#    args = parser.parse_args()\n",
    "#    in_file = args.html_file \n",
    "    \n",
    "    #\"SRR606249_subset10_1.fq.gz FastQC Report.html\"\n",
    "soup = BeautifulSoup(open(SRR606249_subset10_1_fastqc.html),\"html5lib\")\n",
    "graph_alt_names = [\"Per base quality graph\", \"Per sequence quality graph\", \"Per base sequence content\", \"Per sequence GC content graph\", \"N content graph\", \n",
    "                       \"Sequence Length distribution\", \"Duplication level graph\",  \"Adapter graph\", \"Kmer graph\" ]\n",
    "  \n",
    "for image in soup.find_all('img', alt=True):\n",
    "    if (image['alt'] in graph_alt_names):\n",
    "        base64_image_str = image['src']\n",
    "        base64_image_str = base64_image_str[base64_image_str.find(\",\")+1:]\n",
    "        base64_image_str_bytes = bytes(base64_image_str, encoding=\"UTF-8\")\n",
    "        image_64_decode = base64.decodestring(base64_image_str_bytes)\n",
    "        with open(image[\"alt\"], \"wb\")as f:\n",
    "            f.write(image_64_decode)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"/home/oana/data2/SRR606249_subset10_1_fastqc.html\" width=300 height=300></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"/home/oana/data2/SRR606249_subset10_1_fastqc.html\" width=300 height=300></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR606249_subset10_1.fq.gz\n",
      "Approx 5% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 10% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 15% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 20% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 25% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 30% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 35% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 40% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 45% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 50% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 55% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 60% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 65% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 70% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 75% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 80% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 85% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 90% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 95% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 100% complete for SRR606249_subset10_1.fq.gz\n",
      "Analysis complete for SRR606249_subset10_1.fq.gz\n",
      "Started analysis of SRR606249_subset10_2.fq.gz\n",
      "Approx 5% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 10% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 15% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 20% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 25% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 30% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 35% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 40% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 45% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 50% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 55% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 60% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 65% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 70% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 75% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 80% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 85% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 90% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 95% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 100% complete for SRR606249_subset10_2.fq.gz\n",
      "Analysis complete for SRR606249_subset10_2.fq.gz\n"
     ]
    }
   ],
   "source": [
    "#Run fastqc\n",
    "!docker run -v /home/ubuntu/data:/data -it biocontainers/fastqc fastqc /data/SRR606249_subset10_1.fq.gz -o /data/\n",
    "!docker run -v /home/ubuntu/data:/data -it biocontainers/fastqc fastqc /data/SRR606249_subset10_2.fq.gz -o /data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from IPython.display import display\n",
    "display(HTML(filename='/home/oana/data2/SRR606249_subset10_1_fastqc.html'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Trimmomaitc\n",
    "Download TruSeq adapter sequences. Trim the adapters from the datasets, and trim the datasets to a quality score of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   539  100   539    0     0      0      0 --:--:-- --:--:-- --:--:--     0 0     0   1743      0 --:--:-- --:--:-- --:--:--  1744\n"
     ]
    }
   ],
   "source": [
    "#Download TruSeq adapter sequences\n",
    "!curl -O http://dib-training.ucdavis.edu.s3.amazonaws.com/mRNAseq-semi-2015-03-04/TruSeq2-PE.fa\n",
    "!mv TruSeq2-PE.fa /home/ubuntu/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR606249_subset10_1\n",
      "SRR606249_subset10_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/trimmomatic: line 6: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8): No such file or directory\n",
      "TrimmomaticPE: Started with arguments:\n",
      " /data/SRR606249_subset10_1.fq.gz /data/SRR606249_subset10_2.fq.gz /data/SRR606249_subset10_1.trim.fq.gz /data/SRR606249_subset10_1_se /data/SRR606249_subset10_2.trim.fq.gz /data/SRR606249_subset10_2_se ILLUMINACLIP:TruSeq2-PE.fa:2:40:15 LEADING:2 TRAILING:2 SLIDINGWINDOW:4:2 MINLEN:25\n",
      "Multiple cores found: Using 2 threads\n",
      "java.io.FileNotFoundException: /TruSeq2-PE.fa (No such file or directory)\n",
      "\tat java.io.FileInputStream.open0(Native Method)\n",
      "\tat java.io.FileInputStream.open(FileInputStream.java:195)\n",
      "\tat java.io.FileInputStream.<init>(FileInputStream.java:138)\n",
      "\tat org.usadellab.trimmomatic.fasta.FastaParser.parse(FastaParser.java:54)\n",
      "\tat org.usadellab.trimmomatic.trim.IlluminaClippingTrimmer.loadSequences(IlluminaClippingTrimmer.java:110)\n",
      "\tat org.usadellab.trimmomatic.trim.IlluminaClippingTrimmer.makeIlluminaClippingTrimmer(IlluminaClippingTrimmer.java:71)\n",
      "\tat org.usadellab.trimmomatic.trim.TrimmerFactory.makeTrimmer(TrimmerFactory.java:32)\n",
      "\tat org.usadellab.trimmomatic.Trimmomatic.createTrimmers(Trimmomatic.java:59)\n",
      "\tat org.usadellab.trimmomatic.TrimmomaticPE.run(TrimmomaticPE.java:536)\n",
      "\tat org.usadellab.trimmomatic.Trimmomatic.main(Trimmomatic.java:80)\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 5400000 Both Surviving: 5346751 (99.01%) Forward Only Surviving: 24084 (0.45%) Reverse Only Surviving: 28928 (0.54%) Dropped: 237 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "for filename in *_1*.fq.gz\n",
    "do\n",
    "    # first, make the base by removing .fq.gz using the unix program basename\n",
    "    base=$(basename $filename .fq.gz)\n",
    "    echo $base\n",
    "\n",
    "    # now, construct the base2 filename by replacing _1 with _2\n",
    "    base2=${base/_1/_2}\n",
    "    echo $base2\n",
    "\n",
    "    docker run -v /home/ubuntu/data:/data -i quay.io/biocontainers/trimmomatic:0.36--4 trimmomatic PE /data/${base}.fq.gz \\\n",
    "        /data/${base2}.fq.gz \\\n",
    "        /data/${base}.trim.fq.gz /data/${base}_se \\\n",
    "        /data/${base2}.trim.fq.gz /data/${base2}_se \\\n",
    "        ILLUMINACLIP:TruSeq2-PE.fa:2:40:15 \\\n",
    "        LEADING:2 TRAILING:2 \\\n",
    "        SLIDINGWINDOW:4:2 \\\n",
    "        MINLEN:25\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run FastQC quality assesment tool over trimmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 5% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 10% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 15% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 20% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 25% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 30% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 35% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 40% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 45% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 50% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 55% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 60% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 65% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 70% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 75% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 80% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 85% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 90% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Approx 95% complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Analysis complete for SRR606249_subset10_1.trim.fq.gz\n",
      "Started analysis of SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 5% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 10% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 15% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 20% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 25% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 30% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 35% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 40% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 45% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 50% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 55% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 60% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 65% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 70% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 75% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 80% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 85% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 90% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Approx 95% complete for SRR606249_subset10_2.trim.fq.gz\n",
      "Analysis complete for SRR606249_subset10_2.trim.fq.gz\n"
     ]
    }
   ],
   "source": [
    "#Re-asses using FastQC\n",
    "!docker run -v /home/ubuntu/data:/data -it biocontainers/fastqc fastqc /data/SRR606249_subset10_1.trim.fq.gz -o /data/\n",
    "!docker run -v /home/ubuntu/data:/data -it biocontainers/fastqc fastqc /data/SRR606249_subset10_2.trim.fq.gz -o /data/    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interleave paired-end reads using Khmer \n",
    "The output file name includes 'trim2' indicating the reads were trimmed at a quality score of 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR606249_subset10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "|| This is the script interleave-reads.py in khmer.\n",
      "|| You are running khmer version 2.1\n",
      "|| You are also using screed version 1.0\n",
      "||\n",
      "|| If you use this script in a publication, please cite EACH of the following:\n",
      "||\n",
      "||   * MR Crusoe et al., 2015. http://dx.doi.org/10.12688/f1000research.6924.1\n",
      "||\n",
      "|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n",
      "\n",
      "Interleaving:\n",
      "\t/data/SRR606249_subset10_1.trim.fq.gz\n",
      "\t/data/SRR606249_subset10_2.trim.fq.gz\n",
      "... 0 pairs\n",
      "... 100000 pairs\n",
      "... 200000 pairs\n",
      "... 300000 pairs\n",
      "... 400000 pairs\n",
      "... 500000 pairs\n",
      "... 600000 pairs\n",
      "... 700000 pairs\n",
      "... 800000 pairs\n",
      "... 900000 pairs\n",
      "... 1000000 pairs\n",
      "... 1100000 pairs\n",
      "... 1200000 pairs\n",
      "... 1300000 pairs\n",
      "... 1400000 pairs\n",
      "... 1500000 pairs\n",
      "... 1600000 pairs\n",
      "... 1700000 pairs\n",
      "... 1800000 pairs\n",
      "... 1900000 pairs\n",
      "... 2000000 pairs\n",
      "... 2100000 pairs\n",
      "... 2200000 pairs\n",
      "... 2300000 pairs\n",
      "... 2400000 pairs\n",
      "... 2500000 pairs\n",
      "... 2600000 pairs\n",
      "... 2700000 pairs\n",
      "... 2800000 pairs\n",
      "... 2900000 pairs\n",
      "... 3000000 pairs\n",
      "... 3100000 pairs\n",
      "... 3200000 pairs\n",
      "... 3300000 pairs\n",
      "... 3400000 pairs\n",
      "... 3500000 pairs\n",
      "... 3600000 pairs\n",
      "... 3700000 pairs\n",
      "... 3800000 pairs\n",
      "... 3900000 pairs\n",
      "... 4000000 pairs\n",
      "... 4100000 pairs\n",
      "... 4200000 pairs\n",
      "... 4300000 pairs\n",
      "... 4400000 pairs\n",
      "... 4500000 pairs\n",
      "... 4600000 pairs\n",
      "... 4700000 pairs\n",
      "... 4800000 pairs\n",
      "... 4900000 pairs\n",
      "... 5000000 pairs\n",
      "... 5100000 pairs\n",
      "... 5200000 pairs\n",
      "... 5300000 pairs\n",
      "final: interleaved 5346751 pairs\n",
      "output written to /data/SRR606249_subset10.pe.trim2.fq.gz\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /home/oana/data2\n",
    "for filename in *_1.trim.fq.gz\n",
    "do\n",
    "    # first, make the base by removing _1.trim.fq.gz with basename\n",
    "    base=$(basename $filename _1.trim.fq.gz)\n",
    "    echo $base\n",
    "\n",
    "    # construct the output filename\n",
    "    output=${base}.pe.trim2.fq.gz\n",
    "\n",
    "    docker run -v /home/oana/data2:/data -i quay.io/biocontainers/khmer:2.1--py35_0 interleave-reads.py \\\n",
    "        /data/${base}_1.trim.fq.gz /data/${base}_2.trim.fq.gz --no-reformat -o /data/$output --gzip\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
