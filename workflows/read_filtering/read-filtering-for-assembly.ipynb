{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Read Filtering for Assembly Workflow\n",
    "This noteboook installs all docker containers; creates all directories; and runs all programs neccessary to implement a read filtering pipeline for use with metagenomics assembler software. For assembly minimal trimming is performed and the primary goal is to remove aapter sequences. The workflow first enables downloading and generating of all required docker containers, inputs, and drectories. Quality assesments are then executed using FastQC. Datasets are trimmed of adapter TruSeq sequences using Trimmomatic. FastQC dataset analyses are re-calculated over the trimmed datasets. Read 1 and Read 2 sequences are interleaven using Khmer. The example datasets provided as sample imputs are a subset of the Shakya M. et al.(doi 10.1111/1462-2920.12086) dataset which is described in the dataset-characteristics.ipynb notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Install Required Docker Containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: osfclient in /home/oana/py3/lib/python3.5/site-packages\n",
      "Requirement already satisfied: six in /home/oana/py3/lib/python3.5/site-packages (from osfclient)\n",
      "Requirement already satisfied: requests in /home/oana/py3/lib/python3.5/site-packages (from osfclient)\n",
      "Requirement already satisfied: tqdm in /home/oana/py3/lib/python3.5/site-packages (from osfclient)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/oana/py3/lib/python3.5/site-packages (from requests->osfclient)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /home/oana/py3/lib/python3.5/site-packages (from requests->osfclient)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /home/oana/py3/lib/python3.5/site-packages (from requests->osfclient)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/oana/py3/lib/python3.5/site-packages (from requests->osfclient)\n",
      "Using default tag: latest\n",
      "latest: Pulling from biocontainers/fastqc\n",
      "Digest: sha256:7839537b143498ccc32214c4b02a235f7a10b0794064647323de0d5d5957f42b\n",
      "Status: Image is up to date for biocontainers/fastqc:latest\n",
      "0.36--4: Pulling from biocontainers/trimmomatic\n",
      "\n",
      "\u001b[1B95caeb02: Already exists \n",
      "\u001b[1Ba756c345: Already exists \n",
      "\u001b[1B60de4b27: Already exists \n",
      "\u001b[1Bc29a56fb: Already exists \n",
      "\u001b[1Bbb6634fc: Already exists \n",
      "\u001b[1B10677cff: Already exists \n",
      "\u001b[7B95caeb02: Already exists \n",
      "\u001b[1Bb3b2fa0d: Already exists \n",
      "\u001b[1BDigest: sha256:f162a5c4f2644a00e186a6e105e798d4bcdecddb653474ea7e42c915dc6a416b\n",
      "Status: Image is up to date for quay.io/biocontainers/trimmomatic:0.36--4\n",
      "2.1--py35_0: Pulling from biocontainers/khmer\n",
      "\n",
      "\u001b[1B95caeb02: Already exists \n",
      "\u001b[1Bc00e8b61: Already exists \n",
      "\u001b[1Bde50789a: Already exists \n",
      "\u001b[1B8b9f3d2a: Already exists \n",
      "\u001b[1B99a2256f: Already exists \n",
      "\u001b[1B336f2e44: Already exists \n",
      "\u001b[7B95caeb02: Already exists \n",
      "\u001b[1Bbb32200b: Already exists \n",
      "\u001b[1B1b1b4b4f: Already exists Digest: sha256:f82b5f6cc5d57ca9e1b4854f41ea088debaaf2d0b6043a7dc874466433ff35d1\n",
      "Status: Image is up to date for quay.io/biocontainers/khmer:2.1--py35_0\n",
      "2.11--1: Pulling from biocontainers/pandaseq\n",
      "\n",
      "\u001b[1B95caeb02: Already exists \n",
      "\u001b[1Ba756c345: Already exists \n",
      "\u001b[1B60de4b27: Already exists \n",
      "\u001b[1Bc29a56fb: Already exists \n",
      "\u001b[1Bbb6634fc: Already exists \n",
      "\u001b[1B10677cff: Already exists \n",
      "\u001b[7B95caeb02: Already exists \n",
      "\u001b[1Bb3b2fa0d: Already exists \n",
      "\u001b[1Bba8b5542: Pull complete 644MB/2.644MBB\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[K\u001b[1A\u001b[1K\u001b[KDigest: sha256:b4858e79d1bc7a7c40f5f33af34914dfea1007692db4a4fca3e95575b9fa63f5\n",
      "Status: Downloaded newer image for quay.io/biocontainers/pandaseq:2.11--1\n"
     ]
    }
   ],
   "source": [
    "# Install docker containers to run pipeline\n",
    "!docker pull biocontainers/fastqc\n",
    "!docker pull quay.io/biocontainers/trimmomatic:0.36--4\n",
    "!docker pull quay.io/biocontainers/khmer:2.1--py35_0\n",
    "!docker pull quay.io/biocontainers/pandaseq:2.11--1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Set up directories and download input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a working directory (/home/username/data) and download input datasets\n",
    "!mkdir /home/ubuntu/data\n",
    "!cd /home/ubuntu/data\n",
    "!pip install osfclient\n",
    "!osf -p dm938 fetch osfstorage/data/SRR606249_subset10_1.fq.gz\n",
    "!osf -p dm938 fetch osfstorage/data/SRR606249_subset10_2.fq.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run FastQC quality assesment tool over inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 981kB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] html_file\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oana/py3/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2855: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import argparse\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description=\"python module to pull images from the HTML output file\")\n",
    "    parser.add_argument(\"html_file\", help=\"HTML file to get images from \")\n",
    "    args = parser.parse_args()\n",
    "    in_file = args.html_file \n",
    "    \n",
    "    #\"SRR606249_subset10_1.fq.gz FastQC Report.html\"\n",
    "    soup = BeautifulSoup(open(in_file),\"html5lib\")\n",
    "    graph_alt_names = [\"Per base quality graph\", \"Per sequence quality graph\", \"Per base sequence content\", \"Per sequence GC content graph\", \"N content graph\", \n",
    "                       \"Sequence Length distribution\", \"Duplication level graph\",  \"Adapter graph\", \"Kmer graph\" ]\n",
    "  \n",
    "    for image in soup.find_all('img', alt=True):\n",
    "        if (image['alt'] in graph_alt_names):\n",
    "            base64_image_str = image['src']\n",
    "            base64_image_str = base64_image_str[base64_image_str.find(\",\")+1:]\n",
    "            base64_image_str_bytes = bytes(base64_image_str, encoding=\"UTF-8\")\n",
    "            image_64_decode = base64.decodestring(base64_image_str_bytes)\n",
    "            with open(image[\"alt\"], \"wb\")as f:\n",
    "                f.write(image_64_decode)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"/home/oana/data2/SRR606249_subset10_1_fastqc.html\" width=300 height=800></iframe>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe src=\"/home/oana/data2/SRR606249_subset10_1_fastqc.html\" width=300 height=800></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR606249_subset10_1.fq.gz\n",
      "Approx 5% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 10% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 15% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 20% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 25% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 30% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 35% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 40% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 45% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 50% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 55% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 60% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 65% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 70% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 75% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 80% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 85% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 90% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 95% complete for SRR606249_subset10_1.fq.gz\n",
      "Approx 100% complete for SRR606249_subset10_1.fq.gz\n",
      "Analysis complete for SRR606249_subset10_1.fq.gz\n",
      "Started analysis of SRR606249_subset10_2.fq.gz\n",
      "Approx 5% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 10% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 15% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 20% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 25% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 30% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 35% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 40% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 45% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 50% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 55% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 60% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 65% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 70% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 75% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 80% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 85% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 90% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 95% complete for SRR606249_subset10_2.fq.gz\n",
      "Approx 100% complete for SRR606249_subset10_2.fq.gz\n",
      "Analysis complete for SRR606249_subset10_2.fq.gz\n"
     ]
    }
   ],
   "source": [
    "#Run fastqc\n",
    "!docker run -v /home/ubuntu/data:/data -it biocontainers/fastqc fastqc /data/SRR606249_subset10_1.fq.gz -o /data/\n",
    "!docker run -v /home/ubuntu/data:/data -it biocontainers/fastqc fastqc /data/SRR606249_subset10_2.fq.gz -o /data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from IPython.display import display\n",
    "display(HTML(filename='/home/oana/data2/SRR606249_subset10_1_fastqc.html'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Trimmomaitc\n",
    "Download TruSeq adapter sequences. Trim the adapters from the datasets, and trim the datasets to a quality score of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   539  100   539    0     0      0      0 --:--:-- --:--:-- --:--:--     0 0     0   1743      0 --:--:-- --:--:-- --:--:--  1744\n"
     ]
    }
   ],
   "source": [
    "#Download TruSeq adapter sequences\n",
    "!curl -O http://dib-training.ucdavis.edu.s3.amazonaws.com/mRNAseq-semi-2015-03-04/TruSeq2-PE.fa\n",
    "!mv TruSeq2-PE.fa /home/oana/data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR606249_subset10_1\n",
      "SRR606249_subset10_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/trimmomatic: line 6: warning: setlocale: LC_ALL: cannot change locale (en_US.UTF-8): No such file or directory\n",
      "TrimmomaticPE: Started with arguments:\n",
      " /data/SRR606249_subset10_1.fq.gz /data/SRR606249_subset10_2.fq.gz /data/SRR606249_subset10_1.trim.fq.gz /data/SRR606249_subset10_1_se /data/SRR606249_subset10_2.trim.fq.gz /data/SRR606249_subset10_2_se ILLUMINACLIP:TruSeq2-PE.fa:2:40:15 LEADING:2 TRAILING:2 SLIDINGWINDOW:4:2 MINLEN:25\n",
      "Multiple cores found: Using 2 threads\n",
      "java.io.FileNotFoundException: /TruSeq2-PE.fa (No such file or directory)\n",
      "\tat java.io.FileInputStream.open0(Native Method)\n",
      "\tat java.io.FileInputStream.open(FileInputStream.java:195)\n",
      "\tat java.io.FileInputStream.<init>(FileInputStream.java:138)\n",
      "\tat org.usadellab.trimmomatic.fasta.FastaParser.parse(FastaParser.java:54)\n",
      "\tat org.usadellab.trimmomatic.trim.IlluminaClippingTrimmer.loadSequences(IlluminaClippingTrimmer.java:110)\n",
      "\tat org.usadellab.trimmomatic.trim.IlluminaClippingTrimmer.makeIlluminaClippingTrimmer(IlluminaClippingTrimmer.java:71)\n",
      "\tat org.usadellab.trimmomatic.trim.TrimmerFactory.makeTrimmer(TrimmerFactory.java:32)\n",
      "\tat org.usadellab.trimmomatic.Trimmomatic.createTrimmers(Trimmomatic.java:59)\n",
      "\tat org.usadellab.trimmomatic.TrimmomaticPE.run(TrimmomaticPE.java:536)\n",
      "\tat org.usadellab.trimmomatic.Trimmomatic.main(Trimmomatic.java:80)\n",
      "Quality encoding detected as phred33\n",
      "Input Read Pairs: 5400000 Both Surviving: 5346751 (99.01%) Forward Only Surviving: 24084 (0.45%) Reverse Only Surviving: 28928 (0.54%) Dropped: 237 (0.00%)\n",
      "TrimmomaticPE: Completed successfully\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "for filename in *_1*.fq.gz\n",
    "do\n",
    "    # first, make the base by removing .fq.gz using the unix program basename\n",
    "    base=$(basename $filename .fq.gz)\n",
    "    echo $base\n",
    "\n",
    "    # now, construct the base2 filename by replacing _1 with _2\n",
    "    base2=${base/_1/_2}\n",
    "    echo $base2\n",
    "\n",
    "    docker run -v /home/oana/data2:/data -i quay.io/biocontainers/trimmomatic:0.36--4 trimmomatic PE /data/${base}.fq.gz \\\n",
    "        /data/${base2}.fq.gz \\\n",
    "        /data/${base}.trim.fq.gz /data/${base}_se \\\n",
    "        /data/${base2}.trim.fq.gz /data/${base2}_se \\\n",
    "        ILLUMINACLIP:TruSeq2-PE.fa:2:40:15 \\\n",
    "        LEADING:2 TRAILING:2 \\\n",
    "        SLIDINGWINDOW:4:2 \\\n",
    "        MINLEN:25\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run FastQC quality assesment tool over trimmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Re-asses using FastQC\n",
    "docker run -v /home/oana/data2:/data -it biocontainers/fastqc fastqc /data/SRR606249_subset10_1.trim.fq.gz -o /data/\n",
    "docker run -v /home/oana/data2:/data -it biocontainers/fastqc fastqc /data/SRR606249_subset10_2.trim.fq.gz -o /data/    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interleave paired-end reads using Khmer \n",
    "The output file name includes 'trim2' indicating the reads were trimmed at a quality score of 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "for filename in *_1.trim.fq.gz\n",
    "do\n",
    "    # first, make the base by removing _1.trim.fq.gz with basename\n",
    "    base=$(basename $filename _1.trim.fq.gz)\n",
    "    echo $base\n",
    "\n",
    "    # construct the output filename\n",
    "    output=${base}.pe.trim2.fq.gz\n",
    "\n",
    "    docker run -v /home/oana/data2:/data -it quay.io/biocontainers/khmer:2.1--py35_0 interleave-reads.py \\\n",
    "        /data/${base}_1.trim.fq.gz /data/${base}_2.trim.fq.gz --no-reformat -o /data/$output --gzip\n",
    "\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
